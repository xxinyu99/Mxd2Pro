# -*- coding: utf-8 -*-
import arcpy
import os
import shutil
import time

# ================= ğŸš€ é…ç½®åŒºåŸŸ (è¯·ä¿®æ”¹è¿™é‡Œ) =================

# 1. åŸå§‹å·¥ç¨‹è·¯å¾„ (è„šæœ¬ç»ä¸ä¼šä¿®æ”¹è¿™ä¸ªæ–‡ä»¶ï¼Œè¯·æ”¾å¿ƒ)
INPUT_APRX = r"F:\Result\Mxd_To_Pro.aprx"

# 2. ç›®æ ‡æ•°æ®åº“ (GDB æˆ– .sde è¿æ¥æ–‡ä»¶)
TARGET_DB = r"F:\Result\Mxd_To_Pro\Mxd_To_Pro.gdb"

# 3. è¾“å‡ºçš„æ–°å·¥ç¨‹åç§°åç¼€ (ä¾‹å¦‚: Mxd_To_Pro_Fixed.aprx)
OUTPUT_SUFFIX = "_Fixed"

# 4. æ™ºèƒ½åŒ¹é…å…è®¸å¿½ç•¥çš„åç¼€ (ä¸åŒºåˆ†å¤§å°å†™)
# å½“æ‰¾ä¸åˆ°ç²¾ç¡®åŒ¹é…æ—¶ï¼Œå°è¯•å»æ‰è¿™äº›åç¼€å†æ‰¾
IGNORE_SUFFIXES = ["_shp", "_SHP", ".shp", "_merge", "_dissolve", "_New", "Copy"]


# ==========================================================

class SafeUpdater:
    def __init__(self, input_aprx, target_db):
        self.input_aprx = input_aprx
        self.target_db = target_db
        self.working_aprx_path = ""  # å°†åœ¨è¿è¡Œæ—¶ç”Ÿæˆ
        self.db_inventory = {}  # æ•°æ®åº“ç´¢å¼•ç¼“å­˜
        self.logs = []  # è®°å½•æ—¥å¿—ä»¥ä¾¿æœ€åç»Ÿè®¡

    def log(self, msg, level="INFO"):
        """å®æ—¶æ‰“å°å¹¶å­˜å‚¨æ—¥å¿—"""
        timestamp = time.strftime("%H:%M:%S", time.localtime())
        full_msg = f"[{timestamp}] [{level}] {msg}"
        print(full_msg)
        if level in ["ERROR", "WARNING"]:
            self.logs.append(full_msg)

    def prepare_working_copy(self):
        """ã€å®‰å…¨æ ¸å¿ƒã€‘å…ˆç‰©ç†å¤åˆ¶æ–‡ä»¶ï¼Œç¡®ä¿åŸæ–‡ä»¶ç»å¯¹å®‰å…¨"""
        folder = os.path.dirname(self.input_aprx)
        filename = os.path.basename(self.input_aprx)
        name, ext = os.path.splitext(filename)

        # æ„å»ºæ–°æ–‡ä»¶å
        new_filename = f"{name}{OUTPUT_SUFFIX}{ext}"
        self.working_aprx_path = os.path.join(folder, new_filename)

        self.log(f"æ­£åœ¨åˆ›å»ºä½œä¸šå‰¯æœ¬...")
        self.log(f"æºæ–‡ä»¶: {self.input_aprx}")
        self.log(f"æ–°æ–‡ä»¶: {self.working_aprx_path}")

        try:
            # ä½¿ç”¨ shutil è¿›è¡Œç³»ç»Ÿçº§å¤åˆ¶ï¼Œæ¯” arcpy saveACopy æ›´ç¨³å¥
            shutil.copy2(self.input_aprx, self.working_aprx_path)
            self.log("å‰¯æœ¬åˆ›å»ºæˆåŠŸï¼Œåç»­æ‰€æœ‰æ“ä½œå°†åªé’ˆå¯¹æ–°æ–‡ä»¶è¿›è¡Œã€‚")
            return True
        except Exception as e:
            self.log(f"åˆ›å»ºå‰¯æœ¬å¤±è´¥ï¼Œåœæ­¢è¿è¡Œ: {e}", "ERROR")
            return False

    def index_target_db(self):
        """é¢„è¯»å–ç›®æ ‡æ•°æ®åº“ï¼Œå»ºç«‹å†…å­˜ç´¢å¼• (æå¤§æå‡é€Ÿåº¦)"""
        self.log("æ­£åœ¨æ‰«æç›®æ ‡æ•°æ®åº“å†…å®¹...")

        # è®°å½•åŸå§‹ç¯å¢ƒï¼Œé˜²æ­¢å¹²æ‰°
        orig_env = arcpy.env.workspace
        arcpy.env.workspace = self.target_db

        try:
            # è·å–æ‰€æœ‰ FeatureClasses å’Œ Tables
            items = arcpy.ListFeatureClasses() + arcpy.ListTables()

            if not items:
                self.log("ç›®æ ‡æ•°æ®åº“ä¸ºç©ºï¼æ— æ³•è¿›è¡Œæ›´æ–°ã€‚", "ERROR")
                return False

            for item in items:
                # å­˜ä¸¤ä»½ç´¢å¼•ï¼š
                # 1. çœŸå®å…¨å (ç”¨äºæœ€ç»ˆèµ‹å€¼)
                # 2. å°å†™çŸ­å (ç”¨äºå¿½ç•¥ SDE å‰ç¼€å’Œå¤§å°å†™åŒ¹é…)
                #    ä¾‹å¦‚ SDE ä¸­æ˜¯ "sde.owner.Roads"ï¼ŒçŸ­åå­˜ä¸º "roads"
                self.db_inventory[item] = item

                short_name = item.split('.')[-1].lower()
                self.db_inventory[short_name] = item

            self.log(f"ç´¢å¼•å»ºç«‹å®Œæˆï¼Œå…±å‘ç° {len(items)} ä¸ªæ•°æ®é›†ã€‚")
            return True

        except Exception as e:
            self.log(f"è¯»å–æ•°æ®åº“å¤±è´¥: {e}", "ERROR")
            return False
        finally:
            arcpy.env.workspace = orig_env

    def smart_match_dataset(self, old_dataset_name, layer_name):
        """
        æ™ºèƒ½åŒ¹é…ç®—æ³•
        è¿”å›: (åŒ¹é…åˆ°çš„çœŸå®åç§°, åŒ¹é…æ–¹æ³•æè¿°)
        """
        if not old_dataset_name:
            return None, "æ—§æ•°æ®æºåç§°ä¸ºç©º"

        name_lower = old_dataset_name.lower()

        # 1. å°è¯•ï¼šç²¾ç¡®/å¿½ç•¥å¤§å°å†™/å¿½ç•¥SDEå‰ç¼€ åŒ¹é…
        # ç›´æ¥æŸ¥çŸ­åç´¢å¼• (æ¶µç›–äº† Roads -> sde.Roads çš„æƒ…å†µ)
        short_name = name_lower.split('.')[-1]
        if short_name in self.db_inventory:
            return self.db_inventory[short_name], "åç§°åŒ¹é…(å«SDEå‰ç¼€å¤„ç†)"

        # 2. å°è¯•ï¼šæ¸…ç†åç¼€ (ä¾‹å¦‚ Roads_shp -> Roads)
        for suffix in IGNORE_SUFFIXES:
            s_lower = suffix.lower()
            if short_name.endswith(s_lower):
                cleaned = short_name.replace(s_lower, "")
                if cleaned in self.db_inventory:
                    return self.db_inventory[cleaned], f"å»é™¤åç¼€ '{suffix}'"

        # 3. å°è¯•ï¼šåŒ¹é…å›¾å±‚åç§° (ä½œä¸ºæœ€åçš„å¤‡é€‰)
        # æ¯”å¦‚æ•°æ®æºå« Export_Outputï¼Œä½†å›¾å±‚åå« District
        lyr_short = layer_name.lower()
        if lyr_short in self.db_inventory:
            return self.db_inventory[lyr_short], "åŒ¹é…å›¾å±‚åœ¨ç›®å½•çª—æ ¼çš„åç§°"

        return None, None

    def execute(self):
        # 1. å‡†å¤‡å‰¯æœ¬
        if not self.prepare_working_copy(): return

        # 2. ç´¢å¼•æ•°æ®åº“
        if not self.index_target_db(): return

        # 3. æ‰“å¼€å‰¯æœ¬å·¥ç¨‹
        try:
            aprx = arcpy.mp.ArcGISProject(self.working_aprx_path)
        except Exception as e:
            self.log(f"æ— æ³•æ‰“å¼€å·¥ç¨‹æ–‡ä»¶: {e}", "ERROR")
            return

        update_count = 0
        fail_count = 0

        # 4. éå†
        for m in aprx.listMaps():
            self.log(f"--- æ­£åœ¨å¤„ç†åœ°å›¾: {m.name} ---")

            # å¤„ç†å›¾å±‚ + è¡¨æ ¼
            all_layers = m.listLayers() + m.listTables()

            for lyr in all_layers:
                # è¿‡æ»¤ä¸æ”¯æŒçš„å›¾å±‚
                if not hasattr(lyr, "connectionProperties") or not lyr.supports("CONNECTIONPROPERTIES"):
                    continue

                try:
                    cp = lyr.connectionProperties
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆæ³•çš„æ•°æ®è¿æ¥
                    if not cp or 'connection_info' not in cp or 'dataset' not in cp:
                        continue

                    old_ws = cp['connection_info'].get('database', 'æœªçŸ¥è·¯å¾„')
                    old_ds = cp.get('dataset', 'æœªçŸ¥æ•°æ®')

                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ç›®æ ‡è·¯å¾„ (è·¯å¾„æ ‡å‡†åŒ–æ¯”è¾ƒ)
                    if old_ws != 'æœªçŸ¥è·¯å¾„':
                        if os.path.normpath(str(old_ws)).lower() == os.path.normpath(self.target_db).lower():
                            continue  # å·²è¿æ¥ï¼Œè·³è¿‡

                    # === å¯»æ‰¾æ–°æ•°æ®æº ===
                    new_ds_name, match_method = self.smart_match_dataset(old_ds, lyr.name)

                    if not new_ds_name:
                        self.log(f"[è·³è¿‡] {lyr.name}: ç›®æ ‡åº“ä¸­æœªæ‰¾åˆ°å¯¹åº”æ•°æ® (åŸ: {old_ds})", "WARNING")
                        fail_count += 1
                        continue

                    # === æ‰§è¡Œæ›´æ–° ===
                    # æ„é€ æ–°çš„è¿æ¥å±æ€§å­—å…¸
                    new_cp = cp.copy()
                    new_cp['connection_info']['database'] = self.target_db
                    new_cp['dataset'] = new_ds_name

                    print(f"  > æ­£åœ¨ä¿®å¤: {lyr.name}")
                    print(f"    åŸ: {old_ds} | æ–°: {new_ds_name} ({match_method})")

                    lyr.updateConnectionProperties(lyr.connectionProperties, new_cp)

                    if lyr.isBroken:
                        self.log(f"[å¤±è´¥] {lyr.name}: è·¯å¾„å·²ä¿®æ”¹ä½†è¿æ¥æ–­å¼€ (å¯èƒ½æ˜¯å­—æ®µå®šä¹‰ä¸åŒ¹é…)", "ERROR")
                        fail_count += 1
                    else:
                        self.log(f"[æˆåŠŸ] {lyr.name} å·²ä¿®å¤")
                        update_count += 1

                except Exception as e:
                    self.log(f"[å¼‚å¸¸] å¤„ç† {lyr.name} æ—¶å‡ºé”™: {str(e)}", "ERROR")
                    fail_count += 1

        # 5. ä¿å­˜å¹¶æ€»ç»“
        if update_count > 0:
            aprx.save()  # ç›´æ¥ä¿å­˜åˆ°é‚£ä¸ªå‰¯æœ¬é‡Œ
            self.log("=" * 60)
            self.log(f"ä»»åŠ¡ç»“æŸã€‚")
            self.log(f"æˆåŠŸä¿®å¤: {update_count} ä¸ªå›¾å±‚")
            self.log(f"ä¿®å¤å¤±è´¥: {fail_count} ä¸ªå›¾å±‚")
            self.log(f"ç»“æœå·²ä¿å­˜è‡³: {self.working_aprx_path}")
            self.log("=" * 60)
        else:
            self.log("æœªè¿›è¡Œä»»ä½•ä¿®æ”¹ï¼Œåˆ é™¤ä¸´æ—¶å‰¯æœ¬...")
            del aprx
            try:
                os.remove(self.working_aprx_path)
                self.log("å·²æ¸…ç†æœªä¿®æ”¹çš„å‰¯æœ¬ã€‚")
            except:
                pass

        # 6. è¾“å‡ºé”™è¯¯æ±‡æ€»
        if self.logs:
            print("\n--- âš ï¸ å¼‚å¸¸/è­¦å‘Šæ±‡æ€» ---")
            for l in self.logs:
                print(l)


if __name__ == "__main__":
    tool = SafeUpdater(INPUT_APRX, TARGET_DB)
    tool.execute()